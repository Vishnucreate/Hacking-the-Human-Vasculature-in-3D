{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 61446,
          "databundleVersionId": 6962461,
          "sourceType": "competition"
        },
        {
          "sourceId": 7187369,
          "sourceType": "datasetVersion",
          "datasetId": 4087873
        },
        {
          "sourceId": 7308982,
          "sourceType": "datasetVersion",
          "datasetId": 4229452,
          "isSourceIdPinned": true
        },
        {
          "sourceId": 7317471,
          "sourceType": "datasetVersion",
          "datasetId": 4246357,
          "isSourceIdPinned": true
        },
        {
          "sourceId": 150248402,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 156694315,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30588,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Inference. In chans 1. Aug 0.05 e3d60d",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishnucreate/Hacking-the-Human-Vasculature-in-3D/blob/main/Inference_In_chans_1_Aug_0_05_e3d60d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'blood-vessel-segmentation:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F61446%2F6962461%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240126%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240126T183124Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5e6ba459387c1d3dcc73720688e9c71c384d061221b3deb8cfc2cdac429e7a9b95d2277aaaf1574d22bb7d34046ceb82e9b0e81a8f71e64438e35c77c536e15f03e11a796d494f8aeed2a13c2026afe0a723d53c77855aa856c2d89c0cdd424538addcd36da00bece72cfbe0415d9d30f6b649d468577bce468c5330d2ecbd2c4467ded78b7a1531544906ac6b29a706770c6c52fbd965f37b81e270e05d24c0649ebb310c860df2ca840d8726455bf8e5cb1334f090391e85bd8248f17c91dccf6e469c5a0f0c1982d7bff320ad6b5f6ccee6ef5da0b5652d4e8601d4e698ee771b57492687794aeb05a85b4e24961e3157d51d8d8ade4d8456ec6c825d38cf,sennet-model-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4087873%2F7187369%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240126%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240126T183124Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D421ef67b5860d3c2ed9507f175dee812de327b651a37fc78010a7be7b9b96dc43ec7a144c59d1edf600838b97027e48a0f8d0006646af2170812e437b7520c225f90e66aba72cbca933ffbf45df2eadb862e07bbdfcc170bfa58ff88ccef57177bad08b83af7fa4f34759f4b26777f7841ef90d1bf761dc89933b6ca32e29107509ad19c2412a6f456a6807116a5b8fdaea6309698d590a851a0d39789f0562b2412509cd6ea5cdb348234afa8f69b99f3b5bb72c46b31f7af05a503c6f30dd7cc54c6efbfd236a77dda91a7f8029f5d449f5cc7008f1a245f45bce1b9e7ca1decb764c1a2440602ca06dd4e07985f641494aae28a153c30dc9f271b743d6034,training-6-512:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4229452%2F7308982%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240126%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240126T183124Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5038c97064d80d726f5e41c7e21496f0fd099130f79065eac401abcc8abf68c1bbbe25b94e21c7792864167511afc3f9255aca9cd03bf246f2017b6ba55cdc6aef4a0d20365878034f6fe59d9257fe88bda29e72a61128f23866fdf79408c1428cb5f39ce8c9ca3bd4670b356311742c1d58d94beb8b93292753b12a797706e0d072d03f98708c57f73a83a11f72b799b09fdc8f3899ae8077799ee91062b3599780ad4aabb9facc6d77c791326b7c84c3350f6dff3f1af95f192c7c613c116be3dd3d0755fa2613aeb0ad8a353379fd4d99e6152b73f86786201fce7ca5102cbe54c988f6e3243ec5f4977ed54e93e62e9c7e15e980ddc5a6924f0628c407f4,sn-hoa-p-rot-0-3-ep-28:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4246357%2F7317471%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240126%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240126T183124Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4a47905b5cca824b1fd838fde187fc19612bbc944aeead75db7bb5c683add5ff12a58a2933d82203e290378bd7c4ae1df3139de77d4d3d20f2078a4508c471e52159c9eebb678b22014a2b2d5e70596579c3621977552bf8164305566d5246630b805d34a4bc57ddc60cea120ad47d7b211d6b7ab003b3d1bbe057605011ced1108b155cdbf9139a873acb808a4fb01630fec57c0ea2a0c7062e80a38600f6bd98a6e5f8ad6798ea69fab79b94fa342d21014d1b1128ff3a09d8a5fd4abd8a9e35cd75819a64dc57135d2debe7f6c1c12d02e629340d544f3a5d306bba4dab2c11a5ad0b83479ea0c04557d59a1da8fd78a4cdb826e463e6a41eba9eedc57be8'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "MnqayTfACpoC"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference:\n",
        "This notebook 0.849  \n",
        "\n",
        "Version 4\n",
        "\n",
        "model:\n",
        "/kaggle/input/sn-hoa-p-rot-0-3-ep-28/se_resnext50_32x4d_27_loss0.04_score0.90_val_loss0.22_val_score0.87_midd.pt.  From dataset «\n",
        "sn-hoa-p-rot-0-3-ep-28» Version 1 name of version \"Version 1 - Initial release\"\n",
        "\n",
        "idia 0:        \n",
        "        th_percentile = 0.00145                              (-> 0.844)\n",
        "\n",
        "\n",
        "# Train:\n",
        "https://www.kaggle.com/madrismiller/training-rotate-p-0-3  \n",
        "\n",
        "version 1\n",
        "\n",
        "\n",
        "idia 1:\n",
        "\n",
        "        x_index= (x.shape[1]-self.image_size)//2\n",
        "        \n",
        "        y_index= (x.shape[2]-self.image_size)//2   (-> 0.628)\n",
        "        \n",
        "idia 2:\n",
        "     \n",
        "        p_augm = 0.05  #probability of augmentaton changed to 0.05    (-> 0.686)\n",
        "        \n",
        "\n",
        "    \n",
        "idia 3:\n",
        "\n",
        "        in_chans = 1  #window for moov label changed to 1    (-> 0.800)\n",
        "        \n",
        "idia 4:\n",
        "\n",
        "        Epoch = 28                                            (-> 0.823)\n",
        "\n",
        "\n",
        "idia 5:\n",
        "      A.Rotate(.., p= 0.30)"
      ],
      "metadata": {
        "id": "3GOZki_VCpoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All get from:"
      ],
      "metadata": {
        "id": "jLXJW69ACpoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code is base on [2.5d segmentaion baseline [inference]](https://www.kaggle.com/code/tanakar/2-5d-segmentaion-baseline-inference)**\n",
        "If you think my code is useful,please upvote it ^w^.\n",
        "* Version2:\n",
        "1. *     updata normalization method\n",
        "2. *     image_size = 512\n",
        "3. *     useing 3d TTA\n",
        "4. *     se_resnext50_32x4d\n",
        "\n",
        "* Version3:\n",
        "1. *     updata normalization method\n",
        "\n",
        "* This version is correspond with [2.5d segmentaion baseline [training]](https://www.kaggle.com/code/yoyobar/2-5d-cutting-model-baseline-training) version6\n"
      ],
      "metadata": {
        "id": "X83TP_oFCpoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "29ufYdSzCpoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as tc\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import autocast\n",
        "import cv2\n",
        "import os,sys\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "!python -m pip install --no-index --find-links=/kaggle/input/pip-download-for-segmentation-models-pytorch segmentation-models-pytorch\n",
        "import segmentation_models_pytorch as smp\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.parallel import DataParallel\n",
        "from dotenv import load_dotenv\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-12-27T11:33:05.540442Z",
          "iopub.execute_input": "2023-12-27T11:33:05.541375Z",
          "iopub.status.idle": "2023-12-27T11:33:17.485094Z",
          "shell.execute_reply.started": "2023-12-27T11:33:05.541338Z",
          "shell.execute_reply": "2023-12-27T11:33:17.483939Z"
        },
        "trusted": true,
        "id": "4gYt_tzWCpoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# config"
      ],
      "metadata": {
        "id": "ikCmfPQsCpoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path_i = 6 #in_chans_1__25     3 in_chans_1__20 2\n",
        "class CFG:\n",
        "# ============== model CFG =============\n",
        "    model_name = 'Unet'\n",
        "    backbone = 'se_resnext50_32x4d'\n",
        "\n",
        "    in_chans = 1 #5 # 65\n",
        "    #============== _ CFG =============\n",
        "    image_size = 1024\n",
        "    input_size=1024\n",
        "    tile_size = image_size\n",
        "    stride = tile_size // 4\n",
        "    drop_egde_pixel=32 # 16\n",
        "\n",
        "    target_size = 1\n",
        "    chopping_percentile=1e-3\n",
        "    # ============== fold =============\n",
        "    valid_id = 1\n",
        "    batch=32\n",
        "    th_percentile = 0.00146 # 0.0014 #0.00175 #0.0021\n",
        "    model_path=[\"/kaggle/input/2-5d-cutting-model-baseline-training/se_resnext50_32x4d_19_loss0.12_score0.79_val_loss0.25_val_score0.79.pt\",\n",
        "               \"/kaggle/input/training-6-512/se_resnext50_32x4d_19_loss0.09_score0.83_val_loss0.28_val_score0.83.pt\",\n",
        "               \"/kaggle/input/training-6-512/se_resnext50_32x4d_19_loss0.05_score0.90_val_loss0.25_val_score0.86.pt\",\n",
        "               \"/kaggle/input/training-6-512/se_resnext50_32x4d_19_loss0.05_score0.89_val_loss0.24_val_score0.86_midd.pt\",\n",
        "               \"/kaggle/input/training-6-512/se_resnext50_32x4d_24_loss0.05_score0.90_val_loss0.23_val_score0.88_midd.pt\",\n",
        "               \"/kaggle/input/training-6-512/se_resnext50_32x4d_24_loss0.04_score0.91_val_loss0.23_val_score0.88_midd.pt\",\n",
        "               \"/kaggle/input/sn-hoa-p-rot-0-3-ep-28/se_resnext50_32x4d_27_loss0.04_score0.90_val_loss0.22_val_score0.87_midd.pt\",#  Rot = 0.3 ep 28\n",
        "               \"/kaggle/input/sn-hoa-p-rot-0-3-ep-28/se_resnext50_32x4d_27_loss0.04_score0.91_val_loss0.23_val_score0.86_midd.pt\"]#  Rot = 0.2\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T11:33:17.487076Z",
          "iopub.execute_input": "2023-12-27T11:33:17.487395Z",
          "iopub.status.idle": "2023-12-27T11:33:17.493745Z",
          "shell.execute_reply.started": "2023-12-27T11:33:17.487366Z",
          "shell.execute_reply": "2023-12-27T11:33:17.492854Z"
        },
        "trusted": true,
        "id": "YipYispTCpoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "7qZpa6oqCpoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, CFG, weight=None):\n",
        "        super().__init__()\n",
        "        self.CFG = CFG\n",
        "        self.model = smp.Unet(\n",
        "            encoder_name=CFG.backbone,\n",
        "            encoder_weights=weight,\n",
        "            in_channels=CFG.in_chans,\n",
        "            classes=CFG.target_size,\n",
        "            activation=None,\n",
        "        )\n",
        "        self.batch=CFG.batch\n",
        "\n",
        "    def forward_(self, image):\n",
        "        output = self.model(image)\n",
        "        return output[:,0]\n",
        "\n",
        "    def forward(self,x:tc.Tensor):\n",
        "        #x.shape=(batch,c,h,w)\n",
        "        x=x.to(tc.float32)\n",
        "        x=norm_with_clip(x.reshape(-1,*x.shape[2:])).reshape(x.shape)\n",
        "\n",
        "        if CFG.input_size!=CFG.image_size:\n",
        "            x=nn.functional.interpolate(x,size=(CFG.input_size,CFG.input_size),mode='bilinear',align_corners=True)\n",
        "\n",
        "        shape=x.shape\n",
        "        x=[tc.rot90(x,k=i,dims=(-2,-1)) for i in range(4)]\n",
        "        x=tc.cat(x,dim=0)\n",
        "        with autocast():\n",
        "            with tc.no_grad():\n",
        "                x=[self.forward_(x[i*self.batch:(i+1)*self.batch]) for i in range(x.shape[0]//self.batch+1)]\n",
        "                # batch=64,64...48\n",
        "                x=tc.cat(x,dim=0)\n",
        "        x=x.sigmoid()\n",
        "        x=x.reshape(4,shape[0],*shape[2:])\n",
        "        x=[tc.rot90(x[i],k=-i,dims=(-2,-1)) for i in range(4)]\n",
        "        x=tc.stack(x,dim=0).mean(0)\n",
        "\n",
        "        if CFG.input_size!=CFG.image_size:\n",
        "            x=nn.functional.interpolate(x[None],size=(CFG.image_size,CFG.image_size),mode='bilinear',align_corners=True)[0]\n",
        "        return x\n",
        "\n",
        "\n",
        "def build_model(weight=None):\n",
        "    load_dotenv()\n",
        "\n",
        "    print('model_name', CFG.model_name)\n",
        "    print('backbone', CFG.backbone)\n",
        "\n",
        "    model = CustomModel(CFG, weight)\n",
        "\n",
        "    return model.cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T11:33:17.495122Z",
          "iopub.execute_input": "2023-12-27T11:33:17.495479Z",
          "iopub.status.idle": "2023-12-27T11:33:17.511174Z",
          "shell.execute_reply.started": "2023-12-27T11:33:17.495447Z",
          "shell.execute_reply": "2023-12-27T11:33:17.510154Z"
        },
        "trusted": true,
        "id": "UJuZCJUUCpoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "3Bo02TEqCpoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rle_encode(mask):\n",
        "    pixel = mask.flatten()\n",
        "    pixel = np.concatenate([[0], pixel, [0]])\n",
        "    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n",
        "    run[1::2] -= run[::2]\n",
        "    rle = ' '.join(str(r) for r in run)\n",
        "    if rle == '':\n",
        "        rle = '1 0'\n",
        "    return rle\n",
        "\n",
        "def min_max_normalization(x:tc.Tensor)->tc.Tensor:\n",
        "    \"\"\"input.shape=(batch,f1,...)\"\"\"\n",
        "    shape=x.shape\n",
        "    if x.ndim>2:\n",
        "        x=x.reshape(x.shape[0],-1)\n",
        "\n",
        "    min_=x.min(dim=-1,keepdim=True)[0]\n",
        "    max_=x.max(dim=-1,keepdim=True)[0]\n",
        "    if min_.mean()==0 and max_.mean()==1:\n",
        "        return x.reshape(shape)\n",
        "\n",
        "    x=(x-min_)/(max_-min_+1e-9)\n",
        "    return x.reshape(shape)\n",
        "\n",
        "def norm_with_clip(x:tc.Tensor,smooth=1e-5):\n",
        "    dim=list(range(1,x.ndim))\n",
        "    mean=x.mean(dim=dim,keepdim=True)\n",
        "    std=x.std(dim=dim,keepdim=True)\n",
        "    x=(x-mean)/(std+smooth)\n",
        "    x[x>5]=(x[x>5]-5)*1e-3 +5\n",
        "    x[x<-3]=(x[x<-3]+3)*1e-3-3\n",
        "    return x\n",
        "\n",
        "class Data_loader(Dataset):\n",
        "    def __init__(self,path,s=\"/images/\"):\n",
        "        self.paths=glob(path+f\"{s}*.tif\")\n",
        "        self.paths.sort()\n",
        "        self.bool=s==\"/labels/\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img=cv2.imread(self.paths[index],cv2.IMREAD_GRAYSCALE)\n",
        "        img=tc.from_numpy(img)\n",
        "        if self.bool:\n",
        "            img=img.to(tc.bool)\n",
        "        else:\n",
        "            img=img.to(tc.uint8)\n",
        "        return img\n",
        "\n",
        "def load_data(path,s):\n",
        "    data_loader=Data_loader(path,s)\n",
        "    data_loader=DataLoader(data_loader, batch_size=16, num_workers=2)\n",
        "    data=[]\n",
        "    for x in tqdm(data_loader):\n",
        "        data.append(x)\n",
        "    x=tc.cat(data,dim=0)\n",
        "    ########################################################################\n",
        "    TH=x.reshape(-1).numpy()\n",
        "    index = -int(len(TH) * CFG.chopping_percentile)\n",
        "    TH:int = np.partition(TH, index)[index]\n",
        "    x[x>TH]=int(TH)\n",
        "    ########################################################################\n",
        "    TH=x.reshape(-1).numpy()\n",
        "    index = -int(len(TH) * CFG.chopping_percentile)\n",
        "    TH:int = np.partition(TH, -index)[-index]\n",
        "    x[x<TH]=int(TH)\n",
        "    ########################################################################\n",
        "    #x=(min_max_normalization(x.to(tc.float16))*255).to(tc.uint8)\n",
        "    return x\n",
        "\n",
        "class Pipeline_Dataset(Dataset):\n",
        "    def __init__(self,x,path):\n",
        "        self.img_paths  = glob(path+\"/images/*\")\n",
        "        self.img_paths.sort()\n",
        "        self.in_chan = CFG.in_chans\n",
        "        z=tc.zeros(self.in_chan//2,*x.shape[1:],dtype=x.dtype)\n",
        "        self.x=tc.cat((z,x,z),dim=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]-self.in_chan+1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x  = self.x[index:index+self.in_chan]\n",
        "        return x,index\n",
        "\n",
        "    def get_mark(self,index):\n",
        "        id=self.img_paths[index].split(\"/\")[-3:]\n",
        "        id.pop(1)\n",
        "        id=\"_\".join(id)\n",
        "        return id[:-4]\n",
        "\n",
        "    def get_marks(self):\n",
        "        ids=[]\n",
        "        for index in range(len(self)):\n",
        "            ids.append(self.get_mark(index))\n",
        "        return ids\n",
        "\n",
        "def add_edge(x:tc.Tensor,edge:int):\n",
        "    #x=(C,H,W)\n",
        "    #output=(C,H+2*edge,W+2*edge)\n",
        "    mean_=int(x.to(tc.float32).mean())\n",
        "    x=tc.cat([x,tc.ones([x.shape[0],edge,x.shape[2]],dtype=x.dtype,device=x.device)*mean_],dim=1)\n",
        "    x=tc.cat([x,tc.ones([x.shape[0],x.shape[1],edge],dtype=x.dtype,device=x.device)*mean_],dim=2)\n",
        "    x=tc.cat([tc.ones([x.shape[0],edge,x.shape[2]],dtype=x.dtype,device=x.device)*mean_,x],dim=1)\n",
        "    x=tc.cat([tc.ones([x.shape[0],x.shape[1],edge],dtype=x.dtype,device=x.device)*mean_,x],dim=2)\n",
        "    return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T11:33:17.513262Z",
          "iopub.execute_input": "2023-12-27T11:33:17.513522Z",
          "iopub.status.idle": "2023-12-27T11:33:17.540545Z",
          "shell.execute_reply.started": "2023-12-27T11:33:17.513499Z",
          "shell.execute_reply": "2023-12-27T11:33:17.539595Z"
        },
        "trusted": true,
        "id": "WEkhWyyDCpoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build model(s)"
      ],
      "metadata": {
        "id": "CpceCAfzCpoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=build_model()\n",
        "model.load_state_dict(tc.load(CFG.model_path[ model_path_i ],\"cpu\"))\n",
        "model.eval()\n",
        "model=DataParallel(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T11:33:17.541526Z",
          "iopub.execute_input": "2023-12-27T11:33:17.541778Z",
          "iopub.status.idle": "2023-12-27T11:33:18.084421Z",
          "shell.execute_reply.started": "2023-12-27T11:33:17.541755Z",
          "shell.execute_reply": "2023-12-27T11:33:18.083503Z"
        },
        "trusted": true,
        "id": "31P3MIObCpoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output(debug=False):\n",
        "    outputs=[]\n",
        "    if debug:\n",
        "        paths=[\"/kaggle/input/blood-vessel-segmentation/train/kidney_2\"]\n",
        "    else:\n",
        "        paths=glob(\"/kaggle/input/blood-vessel-segmentation/test/*\")\n",
        "    outputs=[[],[]]\n",
        "    for path in paths:\n",
        "        x=load_data(path,\"/images/\")\n",
        "        labels=tc.zeros_like(x,dtype=tc.uint8)\n",
        "        mark=Pipeline_Dataset(x,path).get_marks()\n",
        "        for axis in [0,1,2]:\n",
        "            debug_count=0\n",
        "            if axis==0:\n",
        "                x_=x\n",
        "                labels_=labels\n",
        "            elif axis==1:\n",
        "                x_=x.permute(1,2,0)\n",
        "                labels_=labels.permute(1,2,0)\n",
        "            elif axis==2:\n",
        "                x_=x.permute(2,0,1)\n",
        "                labels_=labels.permute(2,0,1)\n",
        "            if x.shape[0]==3 and axis!=0:\n",
        "                break\n",
        "            dataset=Pipeline_Dataset(x_,path)\n",
        "            dataloader=DataLoader(dataset,batch_size=1,shuffle=False,num_workers=2)\n",
        "            shape=dataset.x.shape[-2:]\n",
        "            x1_list = np.arange(0, shape[0]+CFG.tile_size-CFG.tile_size+1, CFG.stride)\n",
        "            y1_list = np.arange(0, shape[1]+CFG.tile_size-CFG.tile_size+1, CFG.stride)\n",
        "            for img,index in tqdm(dataloader):\n",
        "                #img=(1,C,H,W)\n",
        "                img=img.to(\"cuda:0\")\n",
        "                img=add_edge(img[0],CFG.tile_size//2)[None]\n",
        "\n",
        "                mask_pred = tc.zeros_like(img[:,0],dtype=tc.float32,device=img.device)\n",
        "                mask_count = tc.zeros_like(img[:,0],dtype=tc.float32,device=img.device)\n",
        "\n",
        "                indexs=[]\n",
        "                chip=[]\n",
        "                for y1 in y1_list:\n",
        "                    for x1 in x1_list:\n",
        "                        x2 = x1 + CFG.tile_size\n",
        "                        y2 = y1 + CFG.tile_size\n",
        "                        indexs.append([x1+CFG.drop_egde_pixel,x2-CFG.drop_egde_pixel,\n",
        "                                       y1+CFG.drop_egde_pixel,y2-CFG.drop_egde_pixel])\n",
        "                        chip.append(img[...,x1:x2,y1:y2])\n",
        "\n",
        "                y_preds = model.forward(tc.cat(chip)).to(device=0)\n",
        "\n",
        "                if CFG.drop_egde_pixel:\n",
        "                    y_preds=y_preds[...,CFG.drop_egde_pixel:-CFG.drop_egde_pixel,\n",
        "                                        CFG.drop_egde_pixel:-CFG.drop_egde_pixel]\n",
        "                for i,(x1,x2,y1,y2) in enumerate(indexs):\n",
        "                    mask_pred[...,x1:x2, y1:y2] += y_preds[i]\n",
        "                    mask_count[...,x1:x2, y1:y2] += 1\n",
        "\n",
        "                mask_pred /= mask_count\n",
        "\n",
        "                #Rrecover\n",
        "                mask_pred=mask_pred[...,CFG.tile_size//2:-CFG.tile_size//2,CFG.tile_size//2:-CFG.tile_size//2]\n",
        "\n",
        "                labels_[index]+=(mask_pred[0]*255/3).to(tc.uint8).cpu()\n",
        "                if debug:\n",
        "                    debug_count+=1\n",
        "                    plt.subplot(121)\n",
        "                    plt.imshow(img[0,CFG.in_chans//2].cpu().detach().numpy())\n",
        "                    plt.subplot(122)\n",
        "                    plt.imshow(mask_pred[0].cpu().detach().numpy())\n",
        "                    plt.show()\n",
        "                    if debug_count>3:\n",
        "                        break\n",
        "        outputs[0].append(labels)\n",
        "        outputs[1].extend(mark)\n",
        "    return outputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T11:33:18.085673Z",
          "iopub.execute_input": "2023-12-27T11:33:18.085986Z",
          "iopub.status.idle": "2023-12-27T11:33:18.106261Z",
          "shell.execute_reply.started": "2023-12-27T11:33:18.08596Z",
          "shell.execute_reply": "2023-12-27T11:33:18.105196Z"
        },
        "trusted": true,
        "id": "Jp2FAWzHCpoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_submit=len(glob(\"/kaggle/input/blood-vessel-segmentation/test/kidney_5/images/*.tif\"))!=3\n",
        "#is_submit=True\n",
        "output,ids=get_output(not is_submit)\n",
        "\n",
        "\n",
        "####################################\n",
        "TH=[x.flatten().numpy() for x in output]\n",
        "TH=np.concatenate(TH)\n",
        "index = -int(len(TH) * CFG.th_percentile)\n",
        "TH:int = np.partition(TH, index)[index]\n",
        "print(TH)\n",
        "\n",
        "####################################\n",
        "submission_df=[]\n",
        "debug_count=0\n",
        "for index in range(len(ids)):\n",
        "    id=ids[index]\n",
        "    i=0\n",
        "    for x in output:\n",
        "        if index>=len(x):\n",
        "            index-=len(x)\n",
        "            i+=1\n",
        "        else:\n",
        "            break\n",
        "    mask_pred=(output[i][index]>TH).numpy()\n",
        "    ####################################\n",
        "    if not is_submit:\n",
        "        plt.subplot(121)\n",
        "        plt.imshow(mask_pred)\n",
        "        plt.show()\n",
        "        debug_count+=1\n",
        "        if debug_count>6:\n",
        "            break\n",
        "\n",
        "    rle = rle_encode(mask_pred)\n",
        "\n",
        "    submission_df.append(\n",
        "        pd.DataFrame(data={\n",
        "            'id'  : id,\n",
        "            'rle' : rle,\n",
        "        },index=[0])\n",
        "    )\n",
        "\n",
        "submission_df =pd.concat(submission_df)\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "submission_df.head(6)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T11:33:18.107531Z",
          "iopub.execute_input": "2023-12-27T11:33:18.108202Z",
          "iopub.status.idle": "2023-12-27T11:36:20.192303Z",
          "shell.execute_reply.started": "2023-12-27T11:33:18.108167Z",
          "shell.execute_reply": "2023-12-27T11:36:20.191145Z"
        },
        "trusted": true,
        "id": "tZN6GY--CpoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oo6vNCa_CpoL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}